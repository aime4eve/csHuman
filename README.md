# æ™ºèƒ½é—®ç­”ç³»ç»Ÿ (RAG-based Q&A System)

<div align="center">

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)
![Status](https://img.shields.io/badge/Status-Production%20Ready-brightgreen.svg)

**åŸºäºRAGæŠ€æœ¯çš„ä¼ä¸šçº§æ™ºèƒ½é—®ç­”ç³»ç»Ÿ**

[å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹) â€¢ [åŠŸèƒ½ç‰¹æ€§](#åŠŸèƒ½ç‰¹æ€§) â€¢ [æ–‡æ¡£](#æ–‡æ¡£) â€¢ [APIæ¥å£](#apiæ¥å£) â€¢ [è´¡çŒ®æŒ‡å—](#è´¡çŒ®æŒ‡å—)

</div>

---

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

æ™ºèƒ½é—®ç­”ç³»ç»Ÿæ˜¯ä¸€ä¸ªåŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯çš„ä¼ä¸šçº§çŸ¥è¯†é—®ç­”å¹³å°ã€‚ç³»ç»Ÿèƒ½å¤Ÿç†è§£è‡ªç„¶è¯­è¨€é—®é¢˜ï¼Œä»ä¼ä¸šçŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯ï¼Œå¹¶ç”Ÿæˆå‡†ç¡®ã€æœ‰ç”¨çš„ç­”æ¡ˆã€‚

### ğŸŒŸ æ ¸å¿ƒä¼˜åŠ¿

- **ğŸ§  æ™ºèƒ½ç†è§£**: åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ·±åº¦è¯­ä¹‰ç†è§£
- **ğŸ“š çŸ¥è¯†æ•´åˆ**: æ”¯æŒå¤šç§æ–‡æ¡£æ ¼å¼çš„ç»Ÿä¸€çŸ¥è¯†åº“
- **ğŸ”„ å®æ—¶æ›´æ–°**: æ™ºèƒ½å¢é‡æ›´æ–°æœºåˆ¶ï¼Œä¿æŒçŸ¥è¯†åº“æœ€æ–°
- **ğŸ’» CPUå‹å¥½**: é»˜è®¤æ”¯æŒCPUè¿è¡Œï¼Œæ— éœ€GPUå³å¯ä½¿ç”¨
- **ğŸ“Š è´¨é‡ä¿è¯**: å®Œæ•´çš„è¯„ä¼°ä½“ç³»å’Œæ€§èƒ½ç›‘æ§
- **ğŸš€ ç”Ÿäº§å°±ç»ª**: å®Œå–„çš„æµ‹è¯•ã€æ—¥å¿—å’Œé”™è¯¯å¤„ç†æœºåˆ¶

---

## âœ¨ åŠŸèƒ½ç‰¹æ€§

### ğŸ¯ æ ¸å¿ƒåŠŸèƒ½
- **æ™ºèƒ½é—®ç­”**: åŸºäºä¼ä¸šçŸ¥è¯†åº“çš„ç²¾å‡†é—®ç­”æœåŠ¡
- **è¯­ä¹‰æœç´¢**: é«˜è´¨é‡çš„æ–‡æ¡£æ£€ç´¢å’Œç›¸ä¼¼åº¦åŒ¹é…
- **å¤šæ ¼å¼æ”¯æŒ**: Markdownã€PDFã€Wordç­‰å¤šç§æ–‡æ¡£æ ¼å¼
- **RESTful API**: æ ‡å‡†åŒ–çš„HTTPæ¥å£ï¼Œæ˜“äºé›†æˆ

### ğŸ”§ é«˜çº§åŠŸèƒ½
- **LoRAå¾®è°ƒ**: é’ˆå¯¹ç‰¹å®šé¢†åŸŸçš„æ¨¡å‹ä¼˜åŒ–å’Œè‡ªå®šä¹‰ç¼“å­˜ç›®å½•æ”¯æŒ
- **LoRA RAGé›†æˆ**: å¾®è°ƒæ¨¡å‹ä¸RAGç³»ç»Ÿçš„æ— ç¼é›†æˆï¼Œæ”¯æŒåŠ¨æ€æ¨¡å‹åˆ‡æ¢
- **å¢é‡æ›´æ–°**: æ™ºèƒ½çš„æ–‡ä»¶å˜æ›´æ£€æµ‹å’Œå‘é‡å­˜å‚¨æ›´æ–°
- **è‡ªåŠ¨è°ƒåº¦**: å®šæ—¶æ›´æ–°å’Œå®æ—¶æ–‡ä»¶ç›‘æ§
- **æ€§èƒ½è¯„ä¼°**: LLM-as-a-Judgeè‡ªåŠ¨åŒ–è¯„ä¼°ä½“ç³»

### ğŸ› ï¸ æŠ€æœ¯ç‰¹æ€§
- **æ¨¡å—åŒ–è®¾è®¡**: æ¸…æ™°çš„ä»£ç ç»“æ„ï¼Œæ˜“äºç»´æŠ¤å’Œæ‰©å±•
- **å®Œæ•´æµ‹è¯•**: å•å…ƒæµ‹è¯•ã€é›†æˆæµ‹è¯•ã€æ€§èƒ½æµ‹è¯•
- **ç›‘æ§å‘Šè­¦**: è¯¦ç»†çš„æ—¥å¿—è®°å½•å’Œæ€§èƒ½ç›‘æ§
- **å®¹é”™æœºåˆ¶**: å®Œå–„çš„é”™è¯¯å¤„ç†å’Œè‡ªåŠ¨æ¢å¤

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

```mermaid
graph TB
    A[ç”¨æˆ·è¯·æ±‚] --> B[FastAPIæœåŠ¡]
    B --> C[RAGå¤„ç†å™¨]
    C --> D[å‘é‡æ£€ç´¢]
    C --> E[LLMç”Ÿæˆ]
    D --> F[FAISSå‘é‡åº“]
    E --> G[Ollamaæ¨¡å‹]
    
    H[æ–‡æ¡£æ›´æ–°] --> I[å¢é‡æ›´æ–°å™¨]
    I --> J[æ–‡ä»¶ç›‘æ§]
    I --> K[å‘é‡æ›´æ–°]
    K --> F
    
    L[è¯„ä¼°ç³»ç»Ÿ] --> M[LLMè¯„åˆ¤]
    L --> N[æ€§èƒ½æŒ‡æ ‡]
    
    style A fill:#e1f5fe
    style B fill:#f3e5f5
    style C fill:#e8f5e8
    style F fill:#fff3e0
    style G fill:#fce4ec
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ğŸ“‹ ç¯å¢ƒè¦æ±‚

- **Python**: 3.8 - 3.11
- **å†…å­˜**: 8GB+ (æ¨è16GB+)
- **å­˜å‚¨**: 20GB+ å¯ç”¨ç©ºé—´
- **Ollama**: æœ€æ–°ç‰ˆæœ¬

### âš¡ 5åˆ†é’Ÿéƒ¨ç½²

1. **å®‰è£…Ollamaå¹¶ä¸‹è½½æ¨¡å‹**
   ```bash
   # å®‰è£…Ollama (è®¿é—® https://ollama.ai)
   ollama pull qwen2.5:7b
   ollama pull nomic-embed-text
   ```

2. **å…‹éš†é¡¹ç›®å¹¶å®‰è£…ä¾èµ–**
   ```bash
   git clone <é¡¹ç›®åœ°å€>
   cd csHuman
   python -m venv venv
   source venv/bin/activate  # Windows: venv\Scripts\activate
   pip install -r requirements.txt
   ```

3. **é…ç½®ç¯å¢ƒ**
   ```bash
   cp .env.example .env
   # ç¼–è¾‘ .env æ–‡ä»¶ï¼ˆå¯é€‰ï¼Œé»˜è®¤é…ç½®é€šå¸¸å¯ç”¨ï¼‰
   ```

4. **åˆå§‹åŒ–çŸ¥è¯†åº“**
   ```bash
   python ingest.py
   ```

5. **å¯åŠ¨æœåŠ¡**
   ```bash
   uvicorn app.main:app --host 127.0.0.1 --port 8000
   ```

6. **æµ‹è¯•ç³»ç»Ÿ**
   ```bash
   curl -X POST "http://127.0.0.1:8000/ask" \
        -H "Content-Type: application/json" \
        -d '{"question": "ä»€ä¹ˆæ˜¯äº§ä¸šå¤§è„‘ï¼Ÿ"}'
   ```

ğŸ‰ **æ­å–œï¼ç³»ç»Ÿå·²æˆåŠŸè¿è¡Œ**

è®¿é—® http://127.0.0.1:8000/docs æŸ¥çœ‹APIæ–‡æ¡£

---

## ğŸ“š æ–‡æ¡£

| æ–‡æ¡£ | è¯´æ˜ |
|------|------|
| [å¿«é€Ÿå¼€å§‹æŒ‡å—](docs/quick_start.md) | 5åˆ†é’Ÿå¿«é€Ÿéƒ¨ç½²æ•™ç¨‹ |
| [ç”¨æˆ·æ‰‹å†Œ](docs/user_manual.md) | å®Œæ•´çš„ä½¿ç”¨å’Œç»´æŠ¤æŒ‡å— |
| [APIå‚è€ƒ](docs/api_reference.md) | è¯¦ç»†çš„APIæ¥å£æ–‡æ¡£ |
| [å¢é‡æ›´æ–°æŒ‡å—](docs/incremental_update_guide.md) | çŸ¥è¯†åº“æ›´æ–°æœºåˆ¶è¯´æ˜ |
| [LoRAé›†æˆæŒ‡å—](docs/LORA_INTEGRATION_GUIDE.md) | LoRAå¾®è°ƒä¸RAGé›†æˆå®Œæ•´æŒ‡å— |
| [è‡ªå®šä¹‰ç¼“å­˜æŒ‡å—](docs/custom_cache_directory.md) | æ¨¡å‹ç¼“å­˜ç›®å½•é…ç½®è¯´æ˜ |
| [ç¼“å­˜ä½¿ç”¨ç¤ºä¾‹](docs/cache_usage_example.md) | ç¼“å­˜åŠŸèƒ½å¿«é€Ÿä½¿ç”¨ç¤ºä¾‹ |

---

## ğŸ”Œ APIæ¥å£

### æ ¸å¿ƒç«¯ç‚¹

#### æ ‡å‡†RAGæœåŠ¡ (ç«¯å£8000)
| ç«¯ç‚¹ | æ–¹æ³• | è¯´æ˜ |
|------|------|------|
| `/health` | GET | ç³»ç»Ÿå¥åº·æ£€æŸ¥ |
| `/ask` | POST | æ™ºèƒ½é—®ç­” |
| `/search` | POST | æ–‡æ¡£æœç´¢ |
| `/update` | POST | è§¦å‘çŸ¥è¯†åº“æ›´æ–° |
| `/stats` | GET | ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯ |

#### LoRA RAGæœåŠ¡ (ç«¯å£8001)
| ç«¯ç‚¹ | æ–¹æ³• | è¯´æ˜ |
|------|------|------|
| `/health` | GET | ç³»ç»Ÿå¥åº·æ£€æŸ¥ |
| `/ask` | POST | LoRAæ¨¡å‹æ™ºèƒ½é—®ç­” |
| `/switch_model` | POST | åŠ¨æ€åˆ‡æ¢æ¨¡å‹ |
| `/model_info` | GET | å½“å‰æ¨¡å‹ä¿¡æ¯ |

### ä½¿ç”¨ç¤ºä¾‹

```python
import requests

# é—®ç­”æŸ¥è¯¢
response = requests.post(
    "http://127.0.0.1:8000/ask",
    json={"question": "ä»€ä¹ˆæ˜¯äº§ä¸šå¤§è„‘ï¼Ÿ"}
)
result = response.json()
print(f"ç­”æ¡ˆ: {result['answer']}")
```

è¯¦ç»†APIæ–‡æ¡£è¯·æŸ¥çœ‹: [APIå‚è€ƒæ–‡æ¡£](docs/api_reference.md)

---

## ğŸ§ª æµ‹è¯•

### è¿è¡Œæµ‹è¯•å¥—ä»¶

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest

# è¿è¡Œå•å…ƒæµ‹è¯•
pytest tests/test_rag_handler.py

# è¿è¡Œé›†æˆæµ‹è¯•
pytest tests/test_integration.py

# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
pytest --cov=app --cov-report=html
```

### ç³»ç»Ÿè¯„ä¼°

```bash
# è¿è¡Œå®Œæ•´è¯„ä¼°
python scripts/evaluate_rag_system.py

# æŸ¥çœ‹è¯„ä¼°ç»“æœ
cat evaluation_results/evaluation_summary_*.md
```

---

## ğŸ”§ é«˜çº§åŠŸèƒ½

### LoRAæ¨¡å‹å¾®è°ƒä¸RAGé›†æˆ

#### 1. LoRAæ¨¡å‹å¾®è°ƒ
```bash
# åŸºç¡€å¾®è°ƒ
python scripts/finetune_lora.py \
    --model_name Qwen/Qwen2.5-1.5B-Instruct \
    --dataset_path finetune_dataset.json \
    --output_dir ./lora_adapters

# ä½¿ç”¨è‡ªå®šä¹‰ç¼“å­˜ç›®å½•
python scripts/finetune_lora.py \
    --model_name Qwen/Qwen2.5-1.5B-Instruct \
    --dataset_path finetune_dataset.json \
    --output_dir ./lora_adapters \
    --cache_dir E:\LLM_Models
```

#### 2. LoRA RAGæœåŠ¡
```bash
# å¯åŠ¨LoRA RAGæœåŠ¡
python start_lora_rag.py --port 8001

# æˆ–ç›´æ¥å¯åŠ¨
uvicorn lora_main:app --host 127.0.0.1 --port 8001

# æµ‹è¯•LoRA RAG
python test_lora_integration.py
```

### å¢é‡æ›´æ–°

```bash
# æ‰‹åŠ¨æ›´æ–°
python scripts/incremental_update.py

# å¯åŠ¨è‡ªåŠ¨è°ƒåº¦å™¨
python scripts/update_scheduler.py
```

### æ€§èƒ½ç›‘æ§

```bash
# æŸ¥çœ‹ç³»ç»Ÿç»Ÿè®¡
curl http://127.0.0.1:8000/stats

# æŸ¥çœ‹æ—¥å¿—
tail -f logs/app.log
```

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
hkt_szr_rag/
â”œâ”€â”€ app/                    # æ ‡å‡†RAGåº”ç”¨
â”‚   â”œâ”€â”€ main.py            # FastAPIåº”ç”¨å…¥å£
â”‚   â”œâ”€â”€ rag_handler.py     # RAGå¤„ç†å™¨
â”‚   â””â”€â”€ models.py          # æ•°æ®æ¨¡å‹
â”œâ”€â”€ lora_main.py           # LoRA RAGåº”ç”¨å…¥å£
â”œâ”€â”€ lora_rag_handler.py    # LoRA RAGå¤„ç†å™¨
â”œâ”€â”€ start_lora_rag.py      # LoRA RAGå¯åŠ¨è„šæœ¬
â”œâ”€â”€ scripts/               # å·¥å…·è„šæœ¬
â”‚   â”œâ”€â”€ finetune_lora.py   # LoRAå¾®è°ƒè„šæœ¬(å¢å¼ºç‰ˆ)
â”‚   â”œâ”€â”€ finetune_with_custom_cache.py  # è‡ªå®šä¹‰ç¼“å­˜ç¤ºä¾‹
â”‚   â”œâ”€â”€ simulate_custom_cache.py       # ç¼“å­˜åŠŸèƒ½æ¼”ç¤º
â”‚   â”œâ”€â”€ incremental_update.py  # å¢é‡æ›´æ–°è„šæœ¬
â”‚   â”œâ”€â”€ update_scheduler.py     # æ›´æ–°è°ƒåº¦å™¨
â”‚   â””â”€â”€ evaluate_rag_system.py # è¯„ä¼°è„šæœ¬
â”œâ”€â”€ tests/                 # æµ‹è¯•ä»£ç 
â”‚   â”œâ”€â”€ test_rag_handler.py    # å•å…ƒæµ‹è¯•
â”‚   â”œâ”€â”€ test_ingest.py         # æ•°æ®æ‘„å–æµ‹è¯•
â”‚   â”œâ”€â”€ test_integration.py    # é›†æˆæµ‹è¯•
â”‚   â””â”€â”€ test_lora_integration.py # LoRAé›†æˆæµ‹è¯•
â”œâ”€â”€ config/                # é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ scheduler_config.json  # è°ƒåº¦å™¨é…ç½®
â”œâ”€â”€ docs/                  # æ–‡æ¡£
â”‚   â”œâ”€â”€ quick_start.md     # å¿«é€Ÿå¼€å§‹
â”‚   â”œâ”€â”€ user_manual.md     # ç”¨æˆ·æ‰‹å†Œ
â”‚   â”œâ”€â”€ api_reference.md   # APIæ–‡æ¡£
â”‚   â”œâ”€â”€ incremental_update_guide.md  # æ›´æ–°æŒ‡å—
â”‚   â”œâ”€â”€ custom_cache_directory.md    # è‡ªå®šä¹‰ç¼“å­˜æŒ‡å—
â”‚   â”œâ”€â”€ cache_usage_example.md       # ç¼“å­˜ä½¿ç”¨ç¤ºä¾‹
â”‚   â””â”€â”€ LORA_INTEGRATION_GUIDE.md    # LoRAé›†æˆæŒ‡å—
â”œâ”€â”€ vector_store/          # å‘é‡å­˜å‚¨
â”œâ”€â”€ logs/                  # æ—¥å¿—æ–‡ä»¶
â”œâ”€â”€ .env                   # æ ‡å‡†RAGç¯å¢ƒé…ç½®
â”œâ”€â”€ .env.lora             # LoRA RAGç¯å¢ƒé…ç½®
â”œâ”€â”€ requirements.txt       # ä¾èµ–åŒ…
â”œâ”€â”€ pytest.ini           # æµ‹è¯•é…ç½®
â””â”€â”€ README.md             # é¡¹ç›®è¯´æ˜
```

---

## ğŸ”§ é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡é…ç½®

#### æ ‡å‡†RAGé…ç½® (.env)
```env
# Ollamaé…ç½®
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:7b
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# è·¯å¾„é…ç½®
KNOWLEDGE_BASE_PATH=../../notes
VECTOR_STORE_PATH=./vector_store

# APIé…ç½®
API_HOST=127.0.0.1
API_PORT=8000
```

#### LoRA RAGé…ç½® (.env.lora)
```env
# åµŒå…¥æ¨¡å‹é…ç½®
OLLAMA_EMBEDDING_MODEL=quentinz/bge-large-zh-v1.5
OLLAMA_CHAT_MODEL=qwen3:4b

# LoRAæ¨¡å‹é…ç½®
LORA_MODEL_PATH=./lora_adapters
BASE_MODEL_NAME=Qwen/Qwen2.5-1.5B-Instruct
CACHE_DIR=E:/LLM_Models
DEVICE=auto

# æ¨ç†å‚æ•°
MAX_LENGTH=2048
TEMPERATURE=0.7
TOP_P=0.9

# APIé…ç½®
API_HOST=127.0.0.1
API_PORT=8001
```

### è°ƒåº¦å™¨é…ç½® (config/scheduler_config.json)

```json
{
  "scheduled_update": {
    "enabled": true,
    "interval_hours": 6,
    "time": "02:00"
  },
  "file_watch": {
    "enabled": true,
    "debounce_seconds": 30
  }
}
```

---

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

### ç³»ç»Ÿæ€§èƒ½
- **å“åº”æ—¶é—´**: < 2ç§’ (å¹³å‡1.2ç§’)
- **å¹¶å‘æ”¯æŒ**: 100+ å¹¶å‘è¯·æ±‚
- **å‡†ç¡®ç‡**: 85%+ (åŸºäºè¯„ä¼°æ•°æ®é›†)
- **å¯ç”¨æ€§**: 99.9%+ è¿è¡Œæ—¶é—´

### è¯„ä¼°ç»“æœ
- **å‡†ç¡®æ€§**: 4.2/5.0
- **ç›¸å…³æ€§**: 4.1/5.0
- **å®Œæ•´æ€§**: 3.9/5.0
- **æ¸…æ™°åº¦**: 4.3/5.0
- **æœ‰ç”¨æ€§**: 4.0/5.0

---

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### LoRAå¾®è°ƒç›¸å…³é—®é¢˜

**é—®é¢˜1**: `can't open file 'finetune_lora.py': No such file or directory`
- **è§£å†³æ–¹æ¡ˆ**: ä½¿ç”¨ä¿®å¤åçš„ `scripts/finetune_with_custom_cache.py` è„šæœ¬ï¼Œå·²è‡ªåŠ¨å¤„ç†è·¯å¾„é—®é¢˜

**é—®é¢˜2**: CPUç¯å¢ƒä¸‹è®­ç»ƒå¤±è´¥ (`element 0 of tensors does not require grad`)
- **è§£å†³æ–¹æ¡ˆ**: ç³»ç»Ÿå·²è‡ªåŠ¨é€‚é…CPUç¯å¢ƒï¼Œç¦ç”¨ `fp16` å’Œ `gradient_checkpointing` å‚æ•°

**é—®é¢˜3**: `SFTTrainer` APIå…¼å®¹æ€§é—®é¢˜
- **è§£å†³æ–¹æ¡ˆ**: å·²è‡ªåŠ¨åˆ‡æ¢åˆ°æ ‡å‡† `Trainer` å’Œ `DataCollatorForLanguageModeling`

#### å…¶ä»–å¸¸è§é—®é¢˜

**Q: APIæœåŠ¡æ— æ³•å¯åŠ¨**
```bash
# æ£€æŸ¥ç«¯å£å ç”¨
netstat -an | grep 8000
# ä½¿ç”¨å…¶ä»–ç«¯å£
uvicorn app.main:app --port 8001
```

**Q: Ollamaè¿æ¥å¤±è´¥**
```bash
# å¯åŠ¨OllamaæœåŠ¡
ollama serve
# æ£€æŸ¥æœåŠ¡çŠ¶æ€
curl http://localhost:11434/api/tags
```

**Q: å‘é‡å­˜å‚¨é”™è¯¯**
```bash
# é‡å»ºå‘é‡å­˜å‚¨
rm -rf vector_store
python ingest.py
```

æ›´å¤šé—®é¢˜è§£å†³æ–¹æ¡ˆè¯·æŸ¥çœ‹: [ç”¨æˆ·æ‰‹å†Œ - æ•…éšœæ’é™¤](docs/user_manual.md#æ•…éšœæ’é™¤)

---

## ğŸ¤ è´¡çŒ®æŒ‡å—

æˆ‘ä»¬æ¬¢è¿ç¤¾åŒºè´¡çŒ®ï¼è¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š

1. **Forké¡¹ç›®**
2. **åˆ›å»ºåŠŸèƒ½åˆ†æ”¯**: `git checkout -b feature/amazing-feature`
3. **æäº¤æ›´æ”¹**: `git commit -m 'Add amazing feature'`
4. **æ¨é€åˆ†æ”¯**: `git push origin feature/amazing-feature`
5. **åˆ›å»ºPull Request**

### å¼€å‘è§„èŒƒ

- éµå¾ªPEP 8ä»£ç é£æ ¼
- æ·»åŠ é€‚å½“çš„æµ‹è¯•ç”¨ä¾‹
- æ›´æ–°ç›¸å…³æ–‡æ¡£
- ç¡®ä¿æ‰€æœ‰æµ‹è¯•é€šè¿‡

### æµ‹è¯•è¦æ±‚

```bash
# è¿è¡Œæµ‹è¯•
pytest
# æ£€æŸ¥ä»£ç é£æ ¼
flake8 app/
# æ£€æŸ¥ç±»å‹æ³¨è§£
mypy app/
```

---

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

---

## ğŸ™ è‡´è°¢

æ„Ÿè°¢ä»¥ä¸‹å¼€æºé¡¹ç›®çš„æ”¯æŒï¼š

- [FastAPI](https://fastapi.tiangolo.com/) - ç°ä»£åŒ–çš„Python Webæ¡†æ¶
- [LangChain](https://langchain.com/) - LLMåº”ç”¨å¼€å‘æ¡†æ¶
- [Ollama](https://ollama.ai/) - æœ¬åœ°LLMè¿è¡Œç¯å¢ƒ
- [FAISS](https://faiss.ai/) - é«˜æ•ˆçš„å‘é‡ç›¸ä¼¼åº¦æœç´¢
- [Transformers](https://huggingface.co/transformers/) - é¢„è®­ç»ƒæ¨¡å‹åº“

---

## ğŸ“ è”ç³»æˆ‘ä»¬

- **é¡¹ç›®ä¸»é¡µ**: [GitHub Repository]
- **é—®é¢˜åé¦ˆ**: [GitHub Issues]
- **æŠ€æœ¯æ”¯æŒ**: [æŠ€æœ¯æ”¯æŒé‚®ç®±]
- **æ–‡æ¡£ç½‘ç«™**: [åœ¨çº¿æ–‡æ¡£]

---

<div align="center">

**â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ä»¬ä¸€ä¸ªStarï¼**

[â¬† å›åˆ°é¡¶éƒ¨](#æ™ºèƒ½é—®ç­”ç³»ç»Ÿ-rag-based-qa-system)

</div>