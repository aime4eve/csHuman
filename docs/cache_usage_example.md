
# è‡ªå®šä¹‰ç¼“å­˜ç›®å½•ä½¿ç”¨ç¤ºä¾‹

## 1. å‘½ä»¤è¡Œæ–¹å¼
```bash
python scripts/finetune_lora.py     --model_name_or_path "Qwen/Qwen2.5-1.5B-Instruct"     --cache_dir "E:\LLM_Models"     --output_dir "./lora_adapters"     --num_train_epochs 1     --per_device_train_batch_size 1
```

## 2. ç¯å¢ƒå˜é‡æ–¹å¼
```bash
set HF_HOME=E:\LLM_Models
python scripts/finetune_lora.py --model_name_or_path "Qwen/Qwen2.5-1.5B-Instruct"
```

## 3. Pythonä»£ç æ–¹å¼
```python
import os
os.environ['HF_HOME'] = 'E:\LLM_Models'

# ç„¶åè¿è¡Œå¾®è°ƒè„šæœ¬
```

## ç¼“å­˜ç›®å½•ç»“æ„è¯´æ˜
- models--{org}--{model_name}/: æ¨¡å‹ä¸»ç›®å½•
  - snapshots/{commit_hash}/: ç‰¹å®šç‰ˆæœ¬çš„æ¨¡å‹æ–‡ä»¶
    - config.json: æ¨¡å‹é…ç½®
    - tokenizer.json: åˆ†è¯å™¨
    - model.safetensors: æ¨¡å‹æƒé‡
  - blobs/: äºŒè¿›åˆ¶æ–‡ä»¶å­˜å‚¨
  - refs/: ç‰ˆæœ¬å¼•ç”¨

## ä¼˜åŠ¿
1. ğŸ¯ æŒ‡å®šä¸‹è½½ä½ç½®ï¼Œä¾¿äºç®¡ç†
2. ğŸ’¾ é¿å…é‡å¤ä¸‹è½½ï¼ŒèŠ‚çœç©ºé—´
3. ğŸ”„ å¤šé¡¹ç›®å…±äº«æ¨¡å‹ç¼“å­˜
4. ğŸ“ ç»Ÿä¸€çš„æ¨¡å‹å­˜å‚¨ä½ç½®
