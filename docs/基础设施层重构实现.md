# 基础设施层重构实现

## 1. 概述

本文档详细描述了微调生命周期工作流系统中基础设施层的重构实现，包括Repository模式实现、数据映射逻辑、查询优化和缓存机制，确保基础设施层正确实现领域层定义的接口。

## 2. Repository实现

### 2.1 基础Repository实现

```python
from abc import ABC, abstractmethod
from typing import List, Optional, Dict, Any, TypeVar, Generic
from uuid import UUID
from sqlalchemy.orm import Session
from sqlalchemy import and_, or_, func, text
from sqlalchemy.exc import SQLAlchemyError
import logging

T = TypeVar('T')

class BaseRepository(Generic[T], ABC):
    """基础仓储实现"""
    
    def __init__(self, session: Session, entity_class: type, table_class: type):
        self._session = session
        self._entity_class = entity_class
        self._table_class = table_class
        self._logger = logging.getLogger(self.__class__.__name__)
    
    def save(self, entity: T) -> None:
        """保存实体"""
        try:
            # 将领域实体映射为数据表对象
            table_obj = self._map_entity_to_table(entity)
            
            # 检查是否已存在
            existing = self._session.query(self._table_class).filter(
                self._table_class.id == entity.id
            ).first()
            
            if existing:
                # 更新现有记录
                self._update_table_object(existing, table_obj)
            else:
                # 添加新记录
                self._session.add(table_obj)
            
            self._session.flush()
            self._logger.debug(f"Saved entity {entity.id}")
            
        except SQLAlchemyError as e:
            self._logger.error(f"Failed to save entity {entity.id}: {str(e)}")
            raise RepositoryException(f"Failed to save entity: {str(e)}")
    
    def find_by_id(self, entity_id: UUID) -> Optional[T]:
        """根据ID查找实体"""
        try:
            table_obj = self._session.query(self._table_class).filter(
                self._table_class.id == entity_id
            ).first()
            
            if table_obj:
                return self._map_table_to_entity(table_obj)
            return None
            
        except SQLAlchemyError as e:
            self._logger.error(f"Failed to find entity {entity_id}: {str(e)}")
            raise RepositoryException(f"Failed to find entity: {str(e)}")
    
    def delete(self, entity_id: UUID) -> None:
        """删除实体"""
        try:
            table_obj = self._session.query(self._table_class).filter(
                self._table_class.id == entity_id
            ).first()
            
            if table_obj:
                self._session.delete(table_obj)
                self._session.flush()
                self._logger.debug(f"Deleted entity {entity_id}")
            
        except SQLAlchemyError as e:
            self._logger.error(f"Failed to delete entity {entity_id}: {str(e)}")
            raise RepositoryException(f"Failed to delete entity: {str(e)}")
    
    def find_all(self) -> List[T]:
        """查找所有实体"""
        try:
            table_objs = self._session.query(self._table_class).all()
            return [self._map_table_to_entity(obj) for obj in table_objs]
            
        except SQLAlchemyError as e:
            self._logger.error(f"Failed to find all entities: {str(e)}")
            raise RepositoryException(f"Failed to find entities: {str(e)}")
    
    @abstractmethod
    def _map_entity_to_table(self, entity: T) -> Any:
        """将领域实体映射为数据表对象"""
        pass
    
    @abstractmethod
    def _map_table_to_entity(self, table_obj: Any) -> T:
        """将数据表对象映射为领域实体"""
        pass
    
    def _update_table_object(self, existing: Any, new_data: Any) -> None:
        """更新表对象"""
        for key, value in new_data.__dict__.items():
            if not key.startswith('_'):
                setattr(existing, key, value)

class RepositoryException(Exception):
    """仓储异常"""
    pass
```

### 2.2 知识库Repository实现

```python
from sqlalchemy import Column, String, DateTime, Integer, BigInteger, Text, JSON
from sqlalchemy.dialects.postgresql import UUID as PG_UUID
from sqlalchemy.ext.declarative import declarative_base
from datetime import datetime
from typing import List, Optional

Base = declarative_base()

# 数据表定义
class KnowledgeBaseTable(Base):
    """知识库数据表"""
    __tablename__ = 'knowledge_bases'
    
    id = Column(PG_UUID(as_uuid=True), primary_key=True)
    name = Column(String(255), nullable=False, unique=True)
    description = Column(Text)
    status = Column(String(50), nullable=False)
    document_count = Column(Integer, default=0)
    total_size_bytes = Column(BigInteger, default=0)
    created_at = Column(DateTime, nullable=False)
    updated_at = Column(DateTime, nullable=False)
    owner_id = Column(PG_UUID(as_uuid=True), nullable=False)
    tags = Column(JSON)
    config = Column(JSON)
    vector_store_config = Column(JSON)

class DocumentTable(Base):
    """文档数据表"""
    __tablename__ = 'documents'
    
    id = Column(PG_UUID(as_uuid=True), primary_key=True)
    knowledge_base_id = Column(PG_UUID(as_uuid=True), nullable=False)
    title = Column(String(500), nullable=False)
    file_type = Column(String(50), nullable=False)
    size_bytes = Column(BigInteger, nullable=False)
    status = Column(String(50), nullable=False)
    created_at = Column(DateTime, nullable=False)
    updated_at = Column(DateTime, nullable=False)
    metadata = Column(JSON)
    content_hash = Column(String(64))
    processed_content_path = Column(String(1000))

# Repository实现
class PostgreSQLKnowledgeBaseRepository(BaseRepository[KnowledgeBase], IKnowledgeBaseRepository):
    """PostgreSQL知识库仓储实现"""
    
    def __init__(self, session: Session, cache_service: ICacheService = None):
        super().__init__(session, KnowledgeBase, KnowledgeBaseTable)
        self._cache_service = cache_service
        self._cache_ttl = 300  # 5分钟缓存
    
    def find_by_name(self, name: str) -> Optional[KnowledgeBase]:
        """根据名称查找知识库"""
        try:
            # 尝试从缓存获取
            if self._cache_service:
                cache_key = f"kb:name:{name}"
                cached_result = self._cache_service.get(cache_key)
                if cached_result:
                    return self._deserialize_from_cache(cached_result)
            
            # 从数据库查询
            table_obj = self._session.query(KnowledgeBaseTable).filter(
                KnowledgeBaseTable.name == name
            ).first()
            
            if table_obj:
                entity = self._map_table_to_entity(table_obj)
                
                # 缓存结果
                if self._cache_service:
                    self._cache_service.set(
                        cache_key, 
                        self._serialize_for_cache(entity), 
                        self._cache_ttl
                    )
                
                return entity
            return None
            
        except SQLAlchemyError as e:
            self._logger.error(f"Failed to find knowledge base by name {name}: {str(e)}")
            raise RepositoryException(f"Failed to find knowledge base: {str(e)}")
    
    def find_by_status(self, status: str) -> List[KnowledgeBase]:
        """根据状态查找知识库"""
        try:
            table_objs = self._session.query(KnowledgeBaseTable).filter(
                KnowledgeBaseTable.status == status
            ).all()
            
            return [self._map_table_to_entity(obj) for obj in table_objs]
            
        except SQLAlchemyError as e:
            self._logger.error(f"Failed to find knowledge bases by status {status}: {str(e)}")
            raise RepositoryException(f"Failed to find knowledge bases: {str(e)}")
    
    def find_ready_for_training(self) -> List[KnowledgeBase]:
        """查找可用于训练的知识库"""
        try:
            # 复杂业务查询：状态为READY且文档数量大于0
            table_objs = self._session.query(KnowledgeBaseTable).filter(
                and_(
                    KnowledgeBaseTable.status == 'READY',
                    KnowledgeBaseTable.document_count > 0
                )
            ).all()
            
            return [self._map_table_to_entity(obj) for obj in table_objs]
            
        except SQLAlchemyError as e:
            self._logger.error(f"Failed to find ready knowledge bases: {str(e)}")
            raise RepositoryException(f"Failed to find ready knowledge bases: {str(e)}")
    
    def find_by_owner_id(self, owner_id: UUID) -> List[KnowledgeBase]:
        """根据所有者ID查找知识库"""
        try:
            table_objs = self._session.query(KnowledgeBaseTable).filter(
                KnowledgeBaseTable.owner_id == owner_id
            ).order_by(KnowledgeBaseTable.created_at.desc()).all()
            
            return [self._map_table_to_entity(obj) for obj in table_objs]
            
        except SQLAlchemyError as e:
            self._logger.error(f"Failed to find knowledge bases by owner {owner_id}: {str(e)}")
            raise RepositoryException(f"Failed to find knowledge bases: {str(e)}")
    
    def find_by_tags(self, tags: List[str]) -> List[KnowledgeBase]:
        """根据标签查找知识库"""
        try:
            # 使用JSON查询功能
            conditions = []
            for tag in tags:
                conditions.append(
                    func.json_extract_path_text(KnowledgeBaseTable.tags, tag).isnot(None)
                )
            
            table_objs = self._session.query(KnowledgeBaseTable).filter(
                or_(*conditions)
            ).all()
            
            return [self._map_table_to_entity(obj) for obj in table_objs]
            
        except SQLAlchemyError as e:
            self._logger.error(f"Failed to find knowledge bases by tags {tags}: {str(e)}")
            raise RepositoryException(f"Failed to find knowledge bases: {str(e)}")
    
    def get_statistics(self) -> Dict[str, Any]:
        """获取知识库统计信息"""
        try:
            # 使用聚合查询
            result = self._session.query(
                func.count(KnowledgeBaseTable.id).label('total_count'),
                func.sum(KnowledgeBaseTable.document_count).label('total_documents'),
                func.sum(KnowledgeBaseTable.total_size_bytes).label('total_size'),
                func.count(
                    func.nullif(KnowledgeBaseTable.status != 'READY', False)
                ).label('ready_count')
            ).first()
            
            return {
                'total_knowledge_bases': result.total_count or 0,
                'total_documents': result.total_documents or 0,
                'total_size_bytes': result.total_size or 0,
                'ready_knowledge_bases': result.ready_count or 0
            }
            
        except SQLAlchemyError as e:
            self._logger.error(f"Failed to get statistics: {str(e)}")
            raise RepositoryException(f"Failed to get statistics: {str(e)}")
    
    def _map_entity_to_table(self, entity: KnowledgeBase) -> KnowledgeBaseTable:
        """将领域实体映射为数据表对象"""
        return KnowledgeBaseTable(
            id=entity.id,
            name=entity.name,
            description=entity.description,
            status=entity.status,
            document_count=entity.document_count,
            total_size_bytes=entity.total_size_bytes,
            created_at=entity.created_at,
            updated_at=entity.updated_at,
            owner_id=entity.owner_id,
            tags=entity.tags,
            config=entity.config,
            vector_store_config=entity.vector_store_config
        )
    
    def _map_table_to_entity(self, table_obj: KnowledgeBaseTable) -> KnowledgeBase:
        """将数据表对象映射为领域实体"""
        # 重建聚合根
        kb = KnowledgeBase(
            id=table_obj.id,
            name=table_obj.name,
            description=table_obj.description,
            owner_id=table_obj.owner_id,
            tags=table_obj.tags or [],
            config=table_obj.config or {}
        )
        
        # 设置状态和统计信息
        kb._status = table_obj.status
        kb._document_count = table_obj.document_count
        kb._total_size_bytes = table_obj.total_size_bytes
        kb._created_at = table_obj.created_at
        kb._updated_at = table_obj.updated_at
        kb._vector_store_config = table_obj.vector_store_config or {}
        
        # 加载关联的文档（延迟加载）
        kb._documents = self._load_documents_lazy(table_obj.id)
        
        return kb
    
    def _load_documents_lazy(self, kb_id: UUID) -> List['Document']:
        """延迟加载文档"""
        # 返回一个延迟加载的代理对象
        return DocumentLazyLoader(self._session, kb_id)
    
    def _serialize_for_cache(self, entity: KnowledgeBase) -> Dict[str, Any]:
        """序列化实体用于缓存"""
        return {
            'id': str(entity.id),
            'name': entity.name,
            'description': entity.description,
            'status': entity.status,
            'document_count': entity.document_count,
            'total_size_bytes': entity.total_size_bytes,
            'created_at': entity.created_at.isoformat(),
            'updated_at': entity.updated_at.isoformat(),
            'owner_id': str(entity.owner_id),
            'tags': entity.tags,
            'config': entity.config
        }
    
    def _deserialize_from_cache(self, cached_data: Dict[str, Any]) -> KnowledgeBase:
        """从缓存反序列化实体"""
        # 简化实现，实际应该完整重建对象
        return KnowledgeBase(
            id=UUID(cached_data['id']),
            name=cached_data['name'],
            description=cached_data['description'],
            owner_id=UUID(cached_data['owner_id']),
            tags=cached_data['tags'],
            config=cached_data['config']
        )
```

### 2.3 训练任务Repository实现

```python
class TrainingJobTable(Base):
    """训练任务数据表"""
    __tablename__ = 'training_jobs'
    
    id = Column(PG_UUID(as_uuid=True), primary_key=True)
    job_type = Column(String(50), nullable=False)
    status = Column(String(50), nullable=False)
    knowledge_base_id = Column(PG_UUID(as_uuid=True))
    base_model = Column(String(255))
    base_model_id = Column(PG_UUID(as_uuid=True))
    new_data_id = Column(PG_UUID(as_uuid=True))
    training_config = Column(JSON)
    progress_percentage = Column(Integer, default=0)
    current_epoch = Column(Integer, default=0)
    total_epochs = Column(Integer, default=0)
    created_at = Column(DateTime, nullable=False)
    started_at = Column(DateTime)
    completed_at = Column(DateTime)
    final_model_path = Column(String(1000))
    error_message = Column(Text)
    owner_id = Column(PG_UUID(as_uuid=True), nullable=False)
    resource_usage = Column(JSON)
    checkpoints = Column(JSON)

class PostgreSQLTrainingJobRepository(BaseRepository[TrainingJob], ITrainingJobRepository):
    """PostgreSQL训练任务仓储实现"""
    
    def __init__(self, session: Session, cache_service: ICacheService = None):
        super().__init__(session, TrainingJob, TrainingJobTable)
        self._cache_service = cache_service
    
    def find_by_status(self, status: str) -> List[TrainingJob]:
        """根据状态查找训练任务"""
        try:
            table_objs = self._session.query(TrainingJobTable).filter(
                TrainingJobTable.status == status
            ).order_by(TrainingJobTable.created_at.desc()).all()
            
            return [self._map_table_to_entity(obj) for obj in table_objs]
            
        except SQLAlchemyError as e:
            self._logger.error(f"Failed to find training jobs by status {status}: {str(e)}")
            raise RepositoryException(f"Failed to find training jobs: {str(e)}")
    
    def find_active_jobs(self) -> List[TrainingJob]:
        """查找活跃的训练任务"""
        try:
            active_statuses = ['RUNNING', 'PAUSED', 'PENDING']
            table_objs = self._session.query(TrainingJobTable).filter(
                TrainingJobTable.status.in_(active_statuses)
            ).all()
            
            return [self._map_table_to_entity(obj) for obj in table_objs]
            
        except SQLAlchemyError as e:
            self._logger.error(f"Failed to find active training jobs: {str(e)}")
            raise RepositoryException(f"Failed to find active training jobs: {str(e)}")
    
    def find_by_knowledge_base_id(self, kb_id: UUID) -> List[TrainingJob]:
        """根据知识库ID查找训练任务"""
        try:
            table_objs = self._session.query(TrainingJobTable).filter(
                TrainingJobTable.knowledge_base_id == kb_id
            ).order_by(TrainingJobTable.created_at.desc()).all()
            
            return [self._map_table_to_entity(obj) for obj in table_objs]
            
        except SQLAlchemyError as e:
            self._logger.error(f"Failed to find training jobs by KB {kb_id}: {str(e)}")
            raise RepositoryException(f"Failed to find training jobs: {str(e)}")
    
    def find_completed_jobs_for_incremental(self) -> List[TrainingJob]:
        """查找可用于增量训练的已完成任务"""
        try:
            # 复杂查询：已完成且有最终模型路径的任务
            table_objs = self._session.query(TrainingJobTable).filter(
                and_(
                    TrainingJobTable.status == 'COMPLETED',
                    TrainingJobTable.final_model_path.isnot(None),
                    TrainingJobTable.final_model_path != ''
                )
            ).order_by(TrainingJobTable.completed_at.desc()).all()
            
            return [self._map_table_to_entity(obj) for obj in table_objs]
            
        except SQLAlchemyError as e:
            self._logger.error(f"Failed to find completed jobs: {str(e)}")
            raise RepositoryException(f"Failed to find completed jobs: {str(e)}")
    
    def get_training_statistics(self, owner_id: UUID = None) -> Dict[str, Any]:
        """获取训练统计信息"""
        try:
            query = self._session.query(
                TrainingJobTable.status,
                func.count(TrainingJobTable.id).label('count')
            )
            
            if owner_id:
                query = query.filter(TrainingJobTable.owner_id == owner_id)
            
            results = query.group_by(TrainingJobTable.status).all()
            
            statistics = {result.status: result.count for result in results}
            
            # 添加总计
            statistics['total'] = sum(statistics.values())
            
            return statistics
            
        except SQLAlchemyError as e:
            self._logger.error(f"Failed to get training statistics: {str(e)}")
            raise RepositoryException(f"Failed to get training statistics: {str(e)}")
    
    def _map_entity_to_table(self, entity: TrainingJob) -> TrainingJobTable:
        """将领域实体映射为数据表对象"""
        return TrainingJobTable(
            id=entity.id,
            job_type=entity.job_type,
            status=entity.status,
            knowledge_base_id=entity.knowledge_base_id,
            base_model=entity.base_model,
            base_model_id=entity.base_model_id,
            new_data_id=entity.new_data_id,
            training_config=entity.training_config,
            progress_percentage=entity.progress_percentage,
            current_epoch=entity.current_epoch,
            total_epochs=entity.total_epochs,
            created_at=entity.created_at,
            started_at=entity.started_at,
            completed_at=entity.completed_at,
            final_model_path=entity.final_model_path,
            error_message=entity.error_message,
            owner_id=entity.owner_id,
            resource_usage=entity.resource_usage,
            checkpoints=[cp.__dict__ for cp in entity.checkpoints]
        )
    
    def _map_table_to_entity(self, table_obj: TrainingJobTable) -> TrainingJob:
        """将数据表对象映射为领域实体"""
        # 重建聚合根
        if table_obj.job_type == 'FINE_TUNING':
            job = TrainingJob.create_fine_tuning_job(
                knowledge_base_id=table_obj.knowledge_base_id,
                base_model=table_obj.base_model,
                training_config=table_obj.training_config,
                owner_id=table_obj.owner_id
            )
        else:
            job = TrainingJob.create_incremental_training_job(
                base_model_id=table_obj.base_model_id,
                new_data_id=table_obj.new_data_id,
                training_config=table_obj.training_config,
                owner_id=table_obj.owner_id
            )
        
        # 恢复状态
        job._id = table_obj.id
        job._status = table_obj.status
        job._progress_percentage = table_obj.progress_percentage
        job._current_epoch = table_obj.current_epoch
        job._total_epochs = table_obj.total_epochs
        job._created_at = table_obj.created_at
        job._started_at = table_obj.started_at
        job._completed_at = table_obj.completed_at
        job._final_model_path = table_obj.final_model_path
        job._error_message = table_obj.error_message
        job._resource_usage = table_obj.resource_usage or {}
        
        # 重建检查点
        if table_obj.checkpoints:
            job._checkpoints = [TrainingCheckpoint(**cp) for cp in table_obj.checkpoints]
        
        return job
```

## 3. 查询优化策略

### 3.1 索引设计

```sql
-- 知识库表索引
CREATE INDEX idx_knowledge_bases_name ON knowledge_bases(name);
CREATE INDEX idx_knowledge_bases_status ON knowledge_bases(status);
CREATE INDEX idx_knowledge_bases_owner_id ON knowledge_bases(owner_id);
CREATE INDEX idx_knowledge_bases_created_at ON knowledge_bases(created_at DESC);
CREATE INDEX idx_knowledge_bases_status_documents ON knowledge_bases(status, document_count) WHERE status = 'READY';

-- 文档表索引
CREATE INDEX idx_documents_kb_id ON documents(knowledge_base_id);
CREATE INDEX idx_documents_status ON documents(status);
CREATE INDEX idx_documents_created_at ON documents(created_at DESC);
CREATE INDEX idx_documents_kb_status ON documents(knowledge_base_id, status);

-- 训练任务表索引
CREATE INDEX idx_training_jobs_status ON training_jobs(status);
CREATE INDEX idx_training_jobs_kb_id ON training_jobs(knowledge_base_id);
CREATE INDEX idx_training_jobs_owner_id ON training_jobs(owner_id);
CREATE INDEX idx_training_jobs_created_at ON training_jobs(created_at DESC);
CREATE INDEX idx_training_jobs_status_completed ON training_jobs(status, completed_at) WHERE status = 'COMPLETED';

-- JSON字段索引（PostgreSQL）
CREATE INDEX idx_knowledge_bases_tags_gin ON knowledge_bases USING GIN(tags);
CREATE INDEX idx_training_jobs_config_gin ON training_jobs USING GIN(training_config);
```

### 3.2 查询优化实现

```python
class OptimizedQueryMixin:
    """查询优化混入类"""
    
    def find_with_pagination(self, page: int, page_size: int, 
                           filters: Dict[str, Any] = None) -> Dict[str, Any]:
        """分页查询"""
        try:
            query = self._session.query(self._table_class)
            
            # 应用过滤条件
            if filters:
                query = self._apply_filters(query, filters)
            
            # 计算总数
            total_count = query.count()
            
            # 应用分页
            offset = (page - 1) * page_size
            items = query.offset(offset).limit(page_size).all()
            
            # 转换为实体
            entities = [self._map_table_to_entity(item) for item in items]
            
            return {
                'items': entities,
                'total_count': total_count,
                'page': page,
                'page_size': page_size,
                'total_pages': (total_count + page_size - 1) // page_size
            }
            
        except SQLAlchemyError as e:
            self._logger.error(f"Failed to execute paginated query: {str(e)}")
            raise RepositoryException(f"Failed to execute query: {str(e)}")
    
    def find_with_sorting(self, sort_by: str, sort_order: str = 'asc') -> List[Any]:
        """排序查询"""
        try:
            query = self._session.query(self._table_class)
            
            # 应用排序
            if hasattr(self._table_class, sort_by):
                column = getattr(self._table_class, sort_by)
                if sort_order.lower() == 'desc':
                    query = query.order_by(column.desc())
                else:
                    query = query.order_by(column.asc())
            
            items = query.all()
            return [self._map_table_to_entity(item) for item in items]
            
        except SQLAlchemyError as e:
            self._logger.error(f"Failed to execute sorted query: {str(e)}")
            raise RepositoryException(f"Failed to execute query: {str(e)}")
    
    def _apply_filters(self, query, filters: Dict[str, Any]):
        """应用过滤条件"""
        for key, value in filters.items():
            if hasattr(self._table_class, key):
                column = getattr(self._table_class, key)
                
                if isinstance(value, list):
                    query = query.filter(column.in_(value))
                elif isinstance(value, dict):
                    # 处理范围查询
                    if 'gte' in value:
                        query = query.filter(column >= value['gte'])
                    if 'lte' in value:
                        query = query.filter(column <= value['lte'])
                    if 'like' in value:
                        query = query.filter(column.like(f"%{value['like']}%"))
                else:
                    query = query.filter(column == value)
        
        return query

# 应用到具体Repository
class OptimizedKnowledgeBaseRepository(PostgreSQLKnowledgeBaseRepository, OptimizedQueryMixin):
    """优化的知识库仓储"""
    
    def search_knowledge_bases(self, search_params: Dict[str, Any]) -> Dict[str, Any]:
        """高级搜索"""
        try:
            query = self._session.query(KnowledgeBaseTable)
            
            # 文本搜索
            if 'search_text' in search_params:
                search_text = search_params['search_text']
                query = query.filter(
                    or_(
                        KnowledgeBaseTable.name.ilike(f"%{search_text}%"),
                        KnowledgeBaseTable.description.ilike(f"%{search_text}%")
                    )
                )
            
            # 状态过滤
            if 'statuses' in search_params:
                query = query.filter(
                    KnowledgeBaseTable.status.in_(search_params['statuses'])
                )
            
            # 日期范围过滤
            if 'created_after' in search_params:
                query = query.filter(
                    KnowledgeBaseTable.created_at >= search_params['created_after']
                )
            
            if 'created_before' in search_params:
                query = query.filter(
                    KnowledgeBaseTable.created_at <= search_params['created_before']
                )
            
            # 标签过滤（JSON查询）
            if 'tags' in search_params:
                for tag in search_params['tags']:
                    query = query.filter(
                        func.json_extract_path_text(KnowledgeBaseTable.tags, tag).isnot(None)
                    )
            
            # 应用分页和排序
            page = search_params.get('page', 1)
            page_size = search_params.get('page_size', 20)
            sort_by = search_params.get('sort_by', 'created_at')
            sort_order = search_params.get('sort_order', 'desc')
            
            # 排序
            if hasattr(KnowledgeBaseTable, sort_by):
                column = getattr(KnowledgeBaseTable, sort_by)
                if sort_order.lower() == 'desc':
                    query = query.order_by(column.desc())
                else:
                    query = query.order_by(column.asc())
            
            # 计算总数
            total_count = query.count()
            
            # 分页
            offset = (page - 1) * page_size
            items = query.offset(offset).limit(page_size).all()
            
            # 转换为实体
            entities = [self._map_table_to_entity(item) for item in items]
            
            return {
                'items': entities,
                'total_count': total_count,
                'page': page,
                'page_size': page_size,
                'total_pages': (total_count + page_size - 1) // page_size
            }
            
        except SQLAlchemyError as e:
            self._logger.error(f"Failed to search knowledge bases: {str(e)}")
            raise RepositoryException(f"Failed to search: {str(e)}")
```

## 4. 缓存机制实现

### 4.1 缓存服务接口

```python
from abc import ABC, abstractmethod
from typing import Any, Optional
import json
import pickle
from datetime import datetime, timedelta

class ICacheService(ABC):
    """缓存服务接口"""
    
    @abstractmethod
    def get(self, key: str) -> Optional[Any]:
        """获取缓存值"""
        pass
    
    @abstractmethod
    def set(self, key: str, value: Any, ttl: int = None) -> None:
        """设置缓存值"""
        pass
    
    @abstractmethod
    def delete(self, key: str) -> None:
        """删除缓存"""
        pass
    
    @abstractmethod
    def exists(self, key: str) -> bool:
        """检查缓存是否存在"""
        pass
    
    @abstractmethod
    def clear_pattern(self, pattern: str) -> None:
        """清除匹配模式的缓存"""
        pass

class RedisCacheService(ICacheService):
    """Redis缓存服务实现"""
    
    def __init__(self, redis_client, default_ttl: int = 3600):
        self._redis = redis_client
        self._default_ttl = default_ttl
        self._logger = logging.getLogger(self.__class__.__name__)
    
    def get(self, key: str) -> Optional[Any]:
        """获取缓存值"""
        try:
            value = self._redis.get(key)
            if value:
                return pickle.loads(value)
            return None
        except Exception as e:
            self._logger.error(f"Failed to get cache key {key}: {str(e)}")
            return None
    
    def set(self, key: str, value: Any, ttl: int = None) -> None:
        """设置缓存值"""
        try:
            serialized_value = pickle.dumps(value)
            ttl = ttl or self._default_ttl
            self._redis.setex(key, ttl, serialized_value)
        except Exception as e:
            self._logger.error(f"Failed to set cache key {key}: {str(e)}")
    
    def delete(self, key: str) -> None:
        """删除缓存"""
        try:
            self._redis.delete(key)
        except Exception as e:
            self._logger.error(f"Failed to delete cache key {key}: {str(e)}")
    
    def exists(self, key: str) -> bool:
        """检查缓存是否存在"""
        try:
            return self._redis.exists(key) > 0
        except Exception as e:
            self._logger.error(f"Failed to check cache key {key}: {str(e)}")
            return False
    
    def clear_pattern(self, pattern: str) -> None:
        """清除匹配模式的缓存"""
        try:
            keys = self._redis.keys(pattern)
            if keys:
                self._redis.delete(*keys)
        except Exception as e:
            self._logger.error(f"Failed to clear cache pattern {pattern}: {str(e)}")
```

### 4.2 缓存策略实现

```python
class CacheStrategy:
    """缓存策略"""
    
    def __init__(self, cache_service: ICacheService):
        self._cache_service = cache_service
    
    def get_or_set(self, key: str, factory_func: callable, ttl: int = None) -> Any:
        """获取或设置缓存"""
        # 尝试从缓存获取
        cached_value = self._cache_service.get(key)
        if cached_value is not None:
            return cached_value
        
        # 缓存未命中，调用工厂函数
        value = factory_func()
        
        # 设置缓存
        if value is not None:
            self._cache_service.set(key, value, ttl)
        
        return value
    
    def invalidate_related(self, entity_type: str, entity_id: str) -> None:
        """失效相关缓存"""
        patterns = [
            f"{entity_type}:id:{entity_id}",
            f"{entity_type}:*",
            f"stats:*",
            f"search:*"
        ]
        
        for pattern in patterns:
            self._cache_service.clear_pattern(pattern)

class CachedRepository:
    """带缓存的仓储基类"""
    
    def __init__(self, base_repository, cache_service: ICacheService):
        self._base_repository = base_repository
        self._cache_strategy = CacheStrategy(cache_service)
        self._entity_type = self._base_repository._entity_class.__name__.lower()
    
    def find_by_id(self, entity_id: UUID) -> Optional[Any]:
        """带缓存的ID查找"""
        cache_key = f"{self._entity_type}:id:{entity_id}"
        
        return self._cache_strategy.get_or_set(
            cache_key,
            lambda: self._base_repository.find_by_id(entity_id),
            ttl=300  # 5分钟
        )
    
    def save(self, entity: Any) -> None:
        """保存并失效缓存"""
        # 保存实体
        self._base_repository.save(entity)
        
        # 失效相关缓存
        self._cache_strategy.invalidate_related(self._entity_type, str(entity.id))
    
    def delete(self, entity_id: UUID) -> None:
        """删除并失效缓存"""
        # 删除实体
        self._base_repository.delete(entity_id)
        
        # 失效相关缓存
        self._cache_strategy.invalidate_related(self._entity_type, str(entity_id))
    
    def __getattr__(self, name):
        """代理其他方法到基础仓储"""
        return getattr(self._base_repository, name)
```

## 5. 数据库连接管理

### 5.1 连接池配置

```python
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, scoped_session
from sqlalchemy.pool import QueuePool
import os

class DatabaseManager:
    """数据库管理器"""
    
    def __init__(self, database_url: str):
        self._engine = create_engine(
            database_url,
            poolclass=QueuePool,
            pool_size=20,
            max_overflow=30,
            pool_pre_ping=True,
            pool_recycle=3600,
            echo=os.getenv('SQL_DEBUG', 'false').lower() == 'true'
        )
        
        self._session_factory = sessionmaker(bind=self._engine)
        self._scoped_session = scoped_session(self._session_factory)
    
    def get_session(self):
        """获取数据库会话"""
        return self._scoped_session()
    
    def close_session(self):
        """关闭会话"""
        self._scoped_session.remove()
    
    def create_tables(self):
        """创建表"""
        Base.metadata.create_all(self._engine)
    
    def drop_tables(self):
        """删除表"""
        Base.metadata.drop_all(self._engine)
```

### 5.2 健康检查

```python
class DatabaseHealthCheck:
    """数据库健康检查"""
    
    def __init__(self, database_manager: DatabaseManager):
        self._db_manager = database_manager
        self._logger = logging.getLogger(self.__class__.__name__)
    
    def check_connection(self) -> bool:
        """检查数据库连接"""
        try:
            session = self._db_manager.get_session()
            session.execute(text("SELECT 1"))
            session.close()
            return True
        except Exception as e:
            self._logger.error(f"Database connection check failed: {str(e)}")
            return False
    
    def check_tables(self) -> bool:
        """检查表是否存在"""
        try:
            session = self._db_manager.get_session()
            
            # 检查关键表
            tables_to_check = [
                'knowledge_bases',
                'documents', 
                'training_jobs',
                'evaluation_jobs',
                'workflow_instances'
            ]
            
            for table in tables_to_check:
                result = session.execute(
                    text(f"SELECT 1 FROM information_schema.tables WHERE table_name = '{table}'")
                ).fetchone()
                
                if not result:
                    self._logger.error(f"Table {table} does not exist")
                    return False
            
            session.close()
            return True
            
        except Exception as e:
            self._logger.error(f"Table check failed: {str(e)}")
            return False
    
    def get_health_status(self) -> Dict[str, Any]:
        """获取健康状态"""
        connection_ok = self.check_connection()
        tables_ok = self.check_tables()
        
        return {
            'database_connection': connection_ok,
            'database_tables': tables_ok,
            'overall_health': connection_ok and tables_ok,
            'timestamp': datetime.now().isoformat()
        }
```

## 6. 总结

通过基础设施层重构，我们实现了：

1. **Repository模式**：正确实现了领域层定义的仓储接口
2. **数据映射**：建立了领域实体与数据表之间的映射关系
3. **查询优化**：通过索引设计和查询优化提升性能
4. **缓存机制**：实现了多层缓存策略减少数据库访问
5. **连接管理**：建立了健壮的数据库连接池管理
6. **健康检查**：提供了完整的数据库健康监控

这种重构确保了基础设施层的高性能、高可用性和可维护性，为整个系统提供了坚实的数据访问基础。